# Notazione asintotica

**notazione ğœƒ(ğ‘”(ğ‘›))**

Una funzione f(n) appartiene a ğœƒ(ğ‘”(ğ‘›)) se esistono due
costanti c1 e c2 tali che f(n) possa essere racchiusa tra
c1g(n) e c2g(n).

cioÃ¨ f(n) cresce almeno quanto c1g(n) e al massimo quanto c2(gn), quindi:
* c1g(n) <= f(n) <= c2g(n) 

**notazione O(ğ‘”(ğ‘›))**

f(n) cresce al massimo come cg(n), quindi:
* f(n) <= c2g(n) 

oppure:
* lim f(n) / g(n) = 0

**notazione â„¦(ğ‘”(ğ‘›))**

f(n) cresce al massimo come cg(n), quindi:
* c1g(n) <= f(n)

oppure:
* lim f(n) / g(n) = +inf

# Analisi degli algoritmi

**complessitÃ **

Ã¨ il numero di operazione che l'elaboratore compie su input n
se
< k^n < n!

**algoritmi iterativi**

per calcolare la complessitÃ  degli algoritmi iterativi basta sommare le complessitÃ  delle singole istruzioni e moltiplicare quella dei cicli annidati

**algoritmi iterativi**

la complessitÃ  degli algoritmi ricorsivi Ã¨ data dalla loro formula di ricorrenza

**equazione di ricorrenza**

si indica con T(n), descrive formalmente come viene eseguita la ricorsione, la soluzione di un'equazione di ricorrenza Ã¨ la complessitÃ  dell'algoritmo

di base indica la complessitÃ  su input n, attraverso una scrittura ricorsiva


**metodo di sostituzione**

si cerca ad occhio di capire la complessitÃ  e si dimostra che l'equzione di ricorrenza la rispetta, ci sono 3 casi:
1. T(n) = O(f(n)) --> T(n) <= c*f(n)
2. T(n) = â„¦(f(n)) --> T(n) >= c*f(n)
3. T(n) = ğ›©(f(n)) --> T(n) <= c1\*f(n) e  T(n) >= c2*f(n)

funzionamento:
1. si ottiene la disequazione dai casi sopra
2. si sostituisce T(n) con c*f(n) su argomento di T
3. si risolve la disequazione su c

esempio 1:

dati:
* T(n) = T(n/2) + T(n/4) + n
* dimostrare T(n) = O(n)

soluzione:
* T(n) <= c*f(n) // caso O grande
* T(n/2) + T(n/4) + n <= cn
* cn/2 + cn/4 + n <= cn // sostituisco
* // semplifico
* -c <= -4 --> c >= 4 // soluzione

**dimostrazione con sostituzione**

* si dimostra il caso base della ricorrenza
* si definisce l'ipotesi induttiva, cioÃ¨ assumi che T(n) appartenga alla classe da dimostrare
* si dimostra

esempio
* T(n) = T(n/2) + n
* dimostrare che Ã¨ ğ›©(n)
    * caso base ovvio
    * ipotesi induttiva Ã¨ T(n) <= cn
    * quindi: T(n) = T(n/2) + n <= cn/2 + n
    * se dimostro allora che: cn/2 + n Ã¨ O(n) Ã¨ fatta

**teorema dell'esperto semplice**

risolve le equazioni di ricorrenza nella forma:
* T(n) = aT(n/b) + cn^k

posto:
* j = loga / logb
* a > 1, b >= 2

allora:
* T(n) = ğ›©(n^j) se j > k
* T(n) = ğ›©(n^j * logn) se j = k
* T(n) = ğ›©(n^k) se j < k

**teorema dell'esperto esteso**

risolve le equazioni di ricorrenza nella forma:
* T(n) = aT(n/b) + f(n)

funzionamento:
* l = n^log<sub>b</sub>a
* lim f(n) / n^l = k
* k > 0
    * T(n) = ğ›©(n^l * logn)
* k = 0
    * T(n) = ğ›©(n^l) se
        * lim f(n) / n^(l-epsilon) > 0
* k = +inf
    * T(n) = ğ›©(f(n)) se
        * lim f(n) / n^(l+epsilon) > 0
        * af(n/b) <= cf(n) con 0 < c < 1

**tabella di ricorsione**

rappresenta un albero bilanciato di ricorsione, ha le seguenti colonne:
* livello --> livello corrente dell'albero partendo da 0
* costo chiamata --> costo della singola chiamata di funzione in quel livello
* numero chiamate --> numero di chiamate eseguite in quel livello
* costo livello = costo chiamata * numero chiamate

il costo dell'albero Ã¨ dato da:
* costo albero = somma del costo dei livelli